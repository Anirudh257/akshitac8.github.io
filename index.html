<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <!-- Hi, Jon Here. Please DELETE the two <script> tags below if you use this HTML, otherwise my analytics will track your page -->
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-7580334-2"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-7580334-2');
  </script>

  <title>Akshita Gupta</title>
  
  <meta name="author" content="Akshita Gupta">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/seal_icon.png">
  <style>
    #myimg{
      width:100%;
      max-width:100%;
      border-radius:50%;
      border: 2px solid #ddd;
  padding: 5px;
    }
    
  </style>
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <!-- <p style="text-align:center"> -->
                <!-- <name>Akshita Gupta</name> -->
                <p id="namechange" align="center">
                  <span id="a"><name>Akshita Gupta</name></span><span id="b" style="font-family: 'Gugi', cursive; font-size: 40px;"">अक्षिता गुप्ता </span>
              </p>
              <p style="text-align:justify" >
                I am a research engineer at <a href="http://www.inceptioniai.org/">Inception Institute of Artificial Intelligence</a>. 
                At IIAI, I have worked on research projects dealing with Object Detection, Generative Adversarial Networks and Zero-Shot Learning problems.
                I have also worked on industrial projects in which we tried to solve Texture Classification, Object Detection and Object Counting problems.
              </p>
              <p style="text-align:justify" > 
                I was fortunate to spend a semester during my undergraduate studies at <a href="https://www.iitr.ac.in/">Indian Institute of Technology Roorkee</a>, 
                where I was supervised by <a href="https://scholar.google.co.in/citations?user=QU2O6JMAAAAJ&hl=en">Dr. Balasubramanian Raman</a>.
                Parrallel to my semester at IIT, I was selected as a Outreachy student, with <a href="https://www.mozilla.org/en-GB/">Mozilla</a> <a href="https://www.outreachy.org/alums/">(2018)</a>, where I was supervised by <a href="https://mozillians.org/en-US/u/emmairwin/">Emma Irwin</a>.
                I completed my B.Tech in Computer Science Engineering from DIT University.
              </p>
              <p style="text-align:center">
                <a href="mailto:akshita.sem.iitr@gmail.com">Email</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=G01YeI0AAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a href="https://twitter.com/akshitac8">Twitter</a> &nbsp/&nbsp
                <a href="https://github.com/akshitac8">Github</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/profile_aks.png"><img id = "myimg" alt="profile photo" src="images/profile_aks.png" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="width:100%;vertical-align:middle">
              <heading>What's New</heading>
              <ul>
                <li>[Jul’20] One paper accepted at ECCV’20. </li>
                <li>[Aug’19] A Large-scale Instance Segmentation Dataset for Aerial Images (iSAID) is available for download. </li>
                <li>[Aug’18] One paper accepted at Interspeech, chime workshop 2018. </li>
                <li>[May’18] Selected as a Outreachy Student, with Mozilla. </li>
              </ul>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="width:100%;vertical-align:middle">
            <heading>Research</heading>
            <p>
              I'm interested in developing models which can learn with limited data and few, zero or one training sample(s). 
              Much of my current research is about developing generative models for improving the feature synthesis space for unseen concepts.
            </p>
          </td>
        </tr>
      </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/feedback_vis.png' width="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2003.07833">
                <papertitle>Latent Embedding Feedback and Discriminative Features for Zero-Shot Classification</papertitle>
              </a>
              <br>
              Sanath Narayan<sup>*</sup>,
              <strong><a href="#">Akshita Gupta<sup>*</sup></a></strong>,
              Fahad Shahbaz Khan,
              Cees G. M. Snoek,
              Ling Shao
              <br>
              <em>ECCV</em>, 2020  
              <br>
              <a href="https://github.com/akshitac8/tfvaegan">code</a> /
              <a href="https://www.youtube.com/watch?v=Jq0glS1DwGg&feature=youtu.be">short summary</a> /
              <a href="https://www.youtube.com/watch?v=tNmyfKVUIpo&feature=youtu.be">Overview</a>
              <ul>
                <li>
                  <u>Description:</u> Developed a generative feature synthesizing framework for zero-shot learning.
                </li>
                <li>
                  <u>Outcome:</u> Improved state-of-the-art performances on CUB, FLO, SUN, and AWA by 4.6%, 7.1%, 1.7%, and 3.1% harmonic mean by enforcing semantic consistency at all stages of zero-shot learning.
                </li>
              </ul>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/isaid.png' width="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://captain-whu.github.io/iSAID/">
                <papertitle>iSAID: A Large-scale Dataset for Instance Segmentation in Aerial Images</papertitle>
              </a>
              <br>
              Syed Waqas Zamir,
              Aditya Arora,
              <strong><a href="#">Akshita Gupta</a></strong>,
              Salman Khan,
              Guolei Sun,
              Fahad Shahbaz Khan,
              Fan Zhu,
              Ling Shao,
              Gui-Song Xia,
              Xiang Bai
              <br>
              <em>CVPR Workshop</em>, 2019 <font color="red"><strong>(Oral Presentation)</strong></font> 
              <br>
              <a href="https://github.com/CAPTAIN-WHU/iSAID_Devkit">code</a>
              <ul>
                <li>
                  <u>Description:</u> Improved state of the art object detector (Mask-RCNN and PANet) for aerial imagery.
                </li>
                <li>
                  <u>Outcome:</u> Proposed a large scale instance segmentation and object detection dataset (iSAID) with benchmarking on mask-RCNN and PANet.
                </li>
              </ul>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/interspeech.png' width="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/1811.00936">
                <papertitle>Acoustic features fusion using attentive multi-channel deep architecture</papertitle>
              </a>
              <br>
              Gaurav Bhatt,
              <strong><a href="#">Akshita Gupta</a></strong>,
              Aditya Arora,
              Balasubramanian Raman
              <br>
              <em>Interspeech Workshop</em>, 2018 
              <br>
              <a href="https://github.com/DeepLearn-lab/Acoustic-Feature-Fusion_Chime18">code</a>
              <ul>
                <li>
                  <u>Description:</u> Developed an attention based framework for acoustic scene recognition and audio tagging.
                </li>
                <li>
                  <u>Outcome:</u> Improved the equal error rate by atleast 3% over the Dcase challenge results.
                </li>
              </ul>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tr>
            <td width="100%" valign="middle">
              <heading>Research Experience</heading>
            </td>
          </tr>
        </table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/logo_IIAI.png' width="160" style="background-color:black;padding:10px;">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>Research Engineer, Inception Institute of Artificial Intelligence </papertitle>
              <br>
              <em>Dec 2018 - present</em>
              <br>
              Supervisors: Dr Sanath Narayan, Dr Fahad Shahbaz khan
              <p>
                <ul>
                  <li>Worked on rock & texture classification problem with ADNOC (largest oil & gas company).
                    <ul>
                      <li>In this project, I refined the classification algorithm specifically for the task of rock and texture
                        classification and achieved state of the art results on their collected data.</li>
                      <li>Also worked on a maintaining and deploying the GUI Interface for deploying the algorithm
                        with real-time results.</li>
                    </ul>
                  </li>
                    <li>Developed deep learning models with the satellite imagery team for the task of object detection and counting.
                      <ul>
                        <li><strong>Lead and maintained the main research deployment codes.</strong></li>
                        <li>Object detection: Improved the state of the art (Mask-RCNN and PANet) object detector for the satellite images collected by our company.</li>
                        <li>Counting: Implemented and combined different counting algorithms like LCFCN and LPNs.</li>
                      </ul>
                  </li>
                  <li>Build instance segmentation and object detection models for aerial and satellite imagery. Explored and
                    combined different deep learning models like PAnet and mask-RCNN. Published at CVPR-W Oral 2019.</li>
                  <li>Worked on zero-shot image classification problem using generative adversarial networks. Paper acccepted in ECCV 2020.</li>
                </ul>
                </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:25%">
              <div class="one" style="height:auto;">
                <img src='images/mozilla.jpg' width="160" style="vertical-align:middle">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>Research & Development Intern, Mozilla, Outreachy</papertitle>
              <br>
              <em>May 2018 – Aug 2018</em>
              <br>
              Supervisor: Emma Irwin
              <p> Developed an open source analytics dashboard prototype with the metrics to evaluate diversity and inclusion across different communities.</p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:25%">
              <div class="one" style="height:auto;">
                <img src='images/iitr.jpg' width="160" style="vertical-align:middle">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>Undergraduate Researcher, Indian Institute of Technology</papertitle>
              <br>
              <em>May 2018 – Dec 18</em>
              <br>
              Supervisor: Dr R Balasubramanian
              <p>Worked on acoustic scene recognition and audio tagging using attention networks. Paper accepted in Interspeech-W 2018. </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:25%">
              <div class="one" style="height:auto;">
                <img src='images/iitr.jpg' width="160" style="vertical-align:middle">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>Research Intern, Indian Institute of Technology</papertitle>
              <br>
              <em>May 2017 – Jul 2017</em>
              <br>
              Supervisor: Dr R Balasubramanian
              <p>Worked on Basic Machine Learning techniques such as Support Vector Machines, K-Means Clustering and K-Nearest Neighbors and used these as a baseline for Acoustic Scene Classification.
                Setting up code environments, implemented models which were use for problems of Detection and Classification of Acoustic Scenes and Events.
                Worked on Audio Processing related challenges to minimise Equal Error rate.</p>
            </td>
          </tr>
        </tbody></table>
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td>
            <br>
            <p align="right">
              <font size="2">
              <strong>I borrowed this website layout from <a target="_blank" href="https://jonbarron.info/">here</a>!</strong>
          </font>
            </p>
            </td>
          </tr>
          </table>
      </td>
    </tr>
  </table>
</body>

</html>
