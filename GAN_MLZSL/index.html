<!DOCTYPE html>
<html>

<head lang="en">
    <meta charset="UTF-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">

    <title>CLF</title>

    <meta name="description" content="">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <!-- <base href="/"> -->

        <!--FACEBOOK-->
    <meta property="og:image" content="https://akshitac8.github.io/GAN_MLZSL/img/intro.png">
    <meta property="og:image:type" content="image/png">
    <meta property="og:image:width" content="682">
    <meta property="og:image:height" content="682">
    <meta property="og:type" content="website" />
    <meta property="og:url" content="https://akshitac8.github.io/GAN_MLZSL/"/>
    <meta property="og:title" content="CLF" />
    <meta property="og:description" content="Project page for Generative Multi-Label Zero-Shot Learning" />

        <!--TWITTER-->
    <meta name="twitter:card" content="summary_large_image" />
    <meta name="twitter:title" content="CLF" />
    <meta name="twitter:description" content="Project page for Generative Multi-Label Zero-Shot Learning" />
    <meta name="twitter:image" content="https://akshitac8.github.io/GAN_MLZSL/img/intro.png" />


<!--     <link rel="apple-touch-icon" href="apple-touch-icon.png"> -->
  <!-- <link rel="icon" type="image/png" href="img/seal_icon.png"> -->
    <!-- Place favicon.ico in the root directory -->

    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/css/bootstrap.min.css">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.css">
    <link rel="stylesheet" href="css/app.css">

    <link rel="stylesheet" href="css/bootstrap.min.css">

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/js/bootstrap.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/1.5.3/clipboard.min.js"></script>
    
    <script src="js/app.js"></script>
</head>

<body>
    <div class="container" id="main">
        <div class="row">
            <h2 class="col-md-12 text-center">
                <b>Generative Multi-Label Zero-Shot Learning </br></b>
                <small>
                    <b>aRXIV 2021</b>
                </small>
            </h2>
        </div>
        <div class="row">
            <div class="col-md-12 text-center">
                <ul class="list-inline">
                    <li>
                        <a href="http://akshitac8.github.io/">
                            <b>Akshita Gupta<sup>*</sup></b>
                        </a>
                        </br><b>IIAI</b>
                    </li>
                    <li>
                        <a href="https://sites.google.com/view/sanath-narayan/home">
                          <b>Sanath Narayan<sup>*</sup></b>
                        </a>
                        </br><b>IIAI</b>
                    </li>
                    <li>
                        <a href="https://salman-h-khan.github.io/">
                            <b>Salman Khan</b>
                        </a>
                        </br><b>MBZUAI</b>
                    </li>
                    <li>
                        <a href="https://sites.google.com/view/fahadkhans/home">
                            <b>Fahad Shahbaz Khan</b>
                        </a>
                        </br><b>IIAI, MBZUAI</b>
                    </li><br><br>
                    <li>
                        <a href="https://scholar.google.com/citations?user=z84rLjoAAAAJ&hl=en">
                          <b>Ling Shao</b>
                        </a>
                        </br><b>IIAI, MBZUAI</b>
                    </li>
                    <li>
                        <a href="http://www.cvc.uab.es/LAMP/joost/">
                          <b>Joost van de Weijer</b>
                        </a>
                        </br><b>UAB</b>
                    </li>
                </ul>
            </div>
        </div>
        <div class="row">
                <div class="col-md-4 col-md-offset-4 text-center">
                    <ul class="nav nav-pills nav-justified">
                        <li>
                            <a href="https://arxiv.org/pdf/2101.11606.pdf">
                            <image src="img/GAN_paper.png" height="60px">
                                <h4><strong>Paper</strong></h4>
                            </a>
                        </li>
                        <li>
                            <a href="https://drive.google.com/drive/folders/1tCo-xawWrnGQGaWYJEKQOQ31ts__rAse?usp=sharing">
                            <image src="img/drive_icon.png" height="60px">
                                <h4><strong>training data</strong></h4>
                            </a>
                        </li>
                        <li>
                            <a href="https://github.com/akshitac8/Generative_MLZSL">
                            <image src="img/github.png" height="60px">
                                <h4><strong>Code</strong></h4>
                            </a>
                        </li>
                    </ul>
                </div>
        </div>
        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    <b>Paperswithcode Badges</b>
                </h3>
                    <image src="img/gan_badge.png" class="img-responsive" alt="overview"><br>                
                    <p class="text-justify">
                    Our proposed method CLF, current state-of-the-art for ZSL and GZSL on NUS-WIDE Dataset. Please do consider adding recent ZSL or GZSL results to the same.
                </p>
            </div>
        </div>

        <!--  <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    <b>Video/Overview</b>
                </h3>
                <div class="text-center">
                    <div style="position:relative;padding-top:56.25%;">
                        <iframe src="https://www.youtube.com/embed/tNmyfKVUIpo" allowfullscreen style="position:absolute;top:0;left:0;width:100%;height:100%;"></iframe>
                    </div>
                </div>
            </div>
        </div> -->

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    <b>Abstract</b>
                </h3>
                <p class="text-justify">
Multi-label zero-shot learning strives to classify images into multiple unseen categories for which no data is available during training. The test samples can additionally contain seen categories in the generalized variant. Existing approaches rely on learning either shared or label-specific attention from the seen classes. Nevertheless, computing reliable attention maps for unseen classes during inference in a multi-label setting is still a challenge. In contrast, state-of-the-art single-label generative adversarial network (GAN) based approaches learn to directly synthesize the class-specific visual features from the corresponding class attribute embeddings. However, synthesizing multi-label features from GANs is still unexplored in the context of zero-shot setting.
When multiple objects occur jointly in a single image, a critical question is how to effectively fuse multi-class information. In this work, we introduce different fusion approaches at the attribute-level, feature-level and cross-level (across attribute and feature-levels) for synthesizing multi-label features from their corresponding multi-label class embeddings.
To the best of our knowledge, our work is the first to tackle the problem of multi-label feature synthesis in the (generalized) zero-shot setting. Our cross-level fusion-based generative approach outperforms the state-of-the-art on three zero-shot benchmarks: NUS-WIDE, Open Images and MS COCO. Furthermore, we show the generalization capabilities of our fusion approach in the zero-shot detection task on MS COCO, achieving favorable performance against existing methods.
                </p>
                <image src="img/intro_abs.png" class="img-responsive center-block" alt="overview"><br>
                <image src="img/arch.png" class="img-responsive center-block" alt="overview"><br>
            </div>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    <b>Classification Results</b>
                </h3>
                <p class="text-justify">
                   Below you will find quantitative results for ZSL and GZSL classification in comparison with the previous methods.
                </p>                
                <br>
                <image src="img/table_results_nus.png" class="img-responsive center-block" alt="overview"><br>
                <p class="text-justify">
                   Below you will find qualitative results for ZSL and GZSL task on examples from NUS-WIDE. in comparison with the previous methods. 
                   Alongside each example is a superset of top-5 predictions from our ALF, FLF and CLF. The true- and false-positive classes are enclosed in green and red boxes.
                   For each fusion approach, a green tick (&#9989;) and a red cross (&#10060;) is shown for true- and false-positive labels in its top-5 predictions, respectively.
                   Labels absent in the top-5 predictions of a fusion have no &#9989; or &#10060;.
                </p>                
                <br>
                <image src="img/classification_nus.png" class="img-responsive center-block" alt="overview"><br>
                <image src="img/classification_nus_GZSL.png" class="img-responsive center-block" alt="overview"><br>
                <h3>
                    <b>Detection Results</b>
                </h3>
                <p class="text-justify">
                   Below you will find detection results for GZSD on example images from MS-COCO using our multi-label CLF-based detection approach.
                   The seen and unseen class detections are shown in <font color="red">red</font> and <font color="blue">blue</font>.
                </p>                
                <br>
                <image src="img/detection.png" class="img-responsive center-block" alt="overview"><br>
            </div>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    <b>Citation</b>
                </h3>
                <div class="form-group col-md-10 col-md-offset-1">
                    <textarea id="bibtex" class="form-control" readonly>
@article{gupta2021generative,
  title={Generative Multi-Label Zero-Shot Learning},
  author={Gupta, Akshita and Narayan, Sanath and Khan, Salman and Khan, Fahad Shahbaz and Shao, Ling and van de Weijer, Joost},
  journal={arXiv preprint arXiv:2101.11606},
  year={2021}
}</textarea>
                </div>
            </div>
        </div>
        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    <b>Acknowledgements</b>
                </h3>
                <p class="text-justify">
                I thank <a href="https://hbdat.github.io/">Dat Huynh</a> for discussions and feedback regarding the evaluation protocol and sharing details for the baseline zero-shot methods. I thank  <a href="https://adityac8.github.io/">Aditya Arora</a> for suggestions on the figure aesthetics.
                </p>
            </div>
        </div>
    </div>
</body>
</html>
